{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries and Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import quote_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables from the .env in the local environment    \n",
    "\n",
    "def key_check(key_path=None):\n",
    "    try:\n",
    "        reply=load_dotenv(key_path,verbose=True,override=True)   \n",
    "        assert reply , 'Dotenv is not found'\n",
    "        nyt_api_key = os.getenv(\"NYT_API_KEY\")\n",
    "        tmdb_api_key = os.getenv(\"TMDB_API_KEY\")\n",
    "        assert nyt_api_key is not None, 'NYT_API_KEY not found in .env file'\n",
    "        assert tmdb_api_key is not None, 'TMDB_API_KEY not found in .env file'\n",
    "        responce=requests.get(f'https://api.nytimes.com/svc/mostpopular/v2/viewed/1.json?api-key={nyt_api_key}')\n",
    "        assert responce.status_code == 200, f'The key provided failed to authenticate nyt_api_key {nyt_api_key} code {responce.status_code}'\n",
    "        responce=requests.get(f'https://api.themoviedb.org/3/movie/11?api_key={tmdb_api_key}')\n",
    "        assert responce.status_code == 200, f'The key provided failed to authenticate tmdb_api_key {tmdb_api_key} code {responce.status_code}'\n",
    "    except Exception as e:\n",
    "        # Handle potential errors in loading .env or missing API keys\n",
    "        print(f'An error occurred: {e}')\n",
    "        return(False)\n",
    "    else:\n",
    "        print('All keys loaded correctly')\n",
    "        return (True)\n",
    "my_env_path= 'C:\\src\\\\ai\\data-sourcing-challenge\\.data-sourcing_challenge.env'\n",
    "if key_check(my_env_path):\n",
    "    nyt_api_key = os.getenv(\"NYT_API_KEY\")\n",
    "    tmdb_api_key = os.getenv(\"TMDB_API_KEY\")\n",
    "else:\n",
    "    print ('fix Keys and rerun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the New York Times API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from web page\n",
    "# https://api.nytimes.com/svc/search/v2/articlesearch.json?q=new+york+times&page=2&sort=oldest&api-key=your-api-key \n",
    "\n",
    "#  Set the base URL\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "\n",
    "# Filter for movie reviews with \"love\" in the headline\n",
    "# section_name should be \"Movies\"\n",
    "# type_of_material should be \"Review\"\n",
    "filter_query = quote_plus('section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"')\n",
    "\n",
    "# Use a sort filter, sort by newest\n",
    "sort = \"newest\"\n",
    "\n",
    "# Select the following fields to return:\n",
    "# headline, web_url, snippet, source, keywords, pub_date, byline, word_count\n",
    "field_list = quote_plus(\"headline,web_url,snippet,source,keywords,pub_date,byline,word_count\")\n",
    "\n",
    "# Search for reviews published between a begin and end date\n",
    "begin_date = \"20130101\"\n",
    "end_date = \"20230531\"\n",
    "\n",
    "# Build URL\n",
    "query_url=(f'{url}fq={filter_query}&begin_date={begin_date}&end_date={end_date}&fl={field_list}&sort={sort}&api-key={nyt_api_key}&page=')\n",
    "display (query_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the reviews\n",
    "reviews_list =[]\n",
    "review_page=0\n",
    "# loop through pages 0-19\n",
    "start_page = 0\n",
    "end_page = 20\n",
    "\n",
    "for page in range(start_page,end_page):\n",
    "    # Construct the query URL for the current page\n",
    "    page_url = f'{query_url}{page}'\n",
    "    # Attempt to make a \"GET\" request and parse the JSON response\n",
    "    reviews = requests.get(page_url).json()\n",
    "    try:\n",
    "        # Check if the \"docs\" list is empty; if so, print a message and exit the loop\n",
    "        if (reviews[\"response\"][\"docs\"]):\n",
    "            print(f'Checked page  {page}')\n",
    "            # print ('sleep 12 seconds')\n",
    "            time.sleep(12)                 \n",
    "            # Add a twelve second pause between requests to adhere to API query limits\n",
    "        else: \n",
    "            raise ValueError (f'No results on page {page} {review_page + 1} reviews found, stopping.')\n",
    "    except ValueError as e:\n",
    "        # Handle the case where no documents are found\n",
    "        print(e)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        # Handle potential errors in the request or data processing\n",
    "        print(f'An error occurred: {e}')\n",
    "        break        \n",
    "        # Otherwise, process each article in \"docs\"\n",
    "    for review in reviews[\"response\"][\"docs\"]:\n",
    "        reviews_list.append(review)\n",
    "        review_page += 1\n",
    "        # print (f'review {review_page}' )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print (json.dumps(reviews_list[:5], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews_list to a Pandas DataFrame using json_normalize()\n",
    "review_df=pd.json_normalize(reviews_list)\n",
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to extract\n",
      "display.max_colwidth : int or None\n",
      "    The maximum width in characters of a column in the repr of\n",
      "    a pandas data structure. When the column overflows, a \"...\"\n",
      "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
      "    [default: 50] [currently: 50]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>headline.main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Attachment Diaries</td>\n",
       "      <td>‘The Attachment Diaries’ Review: Love, Sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What’s Love Got to Do With It?</td>\n",
       "      <td>Review: ‘What’s Love Got to Do With It?’ Probably a Lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You Can Live Forever</td>\n",
       "      <td>‘You Can Live Forever’ Review: Do You Love Me Now?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Tourist’s Guide to Love</td>\n",
       "      <td>‘A Tourist’s Guide to Love’ Review: A Wearyingly Familiar Trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other People’s Children</td>\n",
       "      <td>‘Other People’s Children’ Review: True Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>The Other Half</td>\n",
       "      <td>Review: A Combustible Pair Find Love in ‘The Other Half’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>The Ottoman Lieutenant</td>\n",
       "      <td>Review: Love as the World Wars, in ‘The Ottoman Lieutenant’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Love &amp; Taxes</td>\n",
       "      <td>Review: It’s All Mirth and Taxes in ‘Love &amp; Taxes’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Everybody Loves Somebody,</td>\n",
       "      <td>Review: ‘Everybody Loves Somebody,’ a Rom-Com With Bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Kedi,</td>\n",
       "      <td>Review: Cute Cats of ‘Kedi,’ Rekindling a ‘Love of Life’</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "0            The Attachment Diaries   \n",
       "1    What’s Love Got to Do With It?   \n",
       "2              You Can Live Forever   \n",
       "3         A Tourist’s Guide to Love   \n",
       "4           Other People’s Children   \n",
       "..                              ...   \n",
       "195                  The Other Half   \n",
       "196          The Ottoman Lieutenant   \n",
       "197                    Love & Taxes   \n",
       "198       Everybody Loves Somebody,   \n",
       "199                           Kedi,   \n",
       "\n",
       "                                                      headline.main  \n",
       "0                       ‘The Attachment Diaries’ Review: Love, Sick  \n",
       "1           Review: ‘What’s Love Got to Do With It?’ Probably a Lot  \n",
       "2                ‘You Can Live Forever’ Review: Do You Love Me Now?  \n",
       "3    ‘A Tourist’s Guide to Love’ Review: A Wearyingly Familiar Trip  \n",
       "4                    ‘Other People’s Children’ Review: True Romance  \n",
       "..                                                              ...  \n",
       "195        Review: A Combustible Pair Find Love in ‘The Other Half’  \n",
       "196     Review: Love as the World Wars, in ‘The Ottoman Lieutenant’  \n",
       "197              Review: It’s All Mirth and Taxes in ‘Love & Taxes’  \n",
       "198         Review: ‘Everybody Loves Somebody,’ a Rom-Com With Bite  \n",
       "199        Review: Cute Cats of ‘Kedi,’ Rekindling a ‘Love of Life’  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display.max_colwidth : int or None\n",
      "    The maximum width in characters of a column in the repr of\n",
      "    a pandas data structure. When the column overflows, a \"...\"\n",
      "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
      "    [default: 50] [currently: 50]\n"
     ]
    }
   ],
   "source": [
    "# Extract the title from the \"headline.main\" column and\n",
    "# \n",
    "# Regular expression to match text enclosed by ‘ and ’\n",
    "# save it to a new column \"title\"\n",
    "# Title is between unicode characters \\u2018 and \\u2019.\n",
    "# import re\n",
    "\n",
    "import re\n",
    "\n",
    "# Define the lambda function\n",
    "extract_text = lambda st: re.search(r\"(?<=\\u2018)[^‘’]*(?=\\u2019)\", st).group(0) if re.search(r\"(?<=\\u2018)[^‘’]*(?=\\u2019)\", st) else None\n",
    "\n",
    "# Example usage\n",
    "st = \"This is a test ‘text to extract’ and some more text.\"\n",
    "extracted_text = extract_text(st)\n",
    "\n",
    "print(extracted_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# review_df['title'] = review_df['headline.main'].apply(\n",
    "#    lambda st: re.search(r\"(?:\\u0020|^)\\u2018(.+?)\\u2019(?:\\u003A|\\u0020|$)\", st))   \n",
    "review_df['title'] = review_df['headline.main'].apply(\n",
    "    lambda st: re.search(r\"(?:\\u0020|^)\\u2018(.+?)\\u2019(?:\\u003A|\\u0020|$)\", st).group(1) if re.search(r\"\\u2018(.+?)\\u2019\", st) else None)\n",
    "    \n",
    "    # lambda st: st[st.find(\"\\u2018\")+1:st.find(\"\\u2019 Review\")])\n",
    "\n",
    "    #lambda st: st[st.find(\"(?:\\u0020|^)\\u2018\")+1:st.find(\"\\u2019(?:\\u003A|\\u0020|$\")])\n",
    "pd.describe_option('display.max_colwidth')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display (review_df[['title','headline.main']])\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.describe_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'name' and 'value' from items in \"keywords\" column\n",
    "def extract_keywords(keyword_list):\n",
    "    extracted_keywords = \"\"\n",
    "    for item in keyword_list:\n",
    "        # Extract 'name' and 'value'\n",
    "        keyword = f\"{item['name']}: {item['value']};\" \n",
    "        # Append the keyword item to the extracted_keywords list\n",
    "        extracted_keywords += keyword\n",
    "    return extracted_keywords\n",
    "\n",
    "# this copy make it possible for me to rerun this without having to start from scratch\n",
    "review_mod_df = review_df.copy(deep=True)\n",
    "\n",
    "# Fix the \"keywords\" column by converting cells from a list to a string\n",
    "review_mod_df['keywords'] = review_mod_df['keywords'].apply(extract_keywords)\n",
    "# display(lmr_keyword_df[['title','keywords']].head(3))\n",
    "#\n",
    "#play time with style\n",
    "styled_subset_df=review_mod_df.loc[:4,['title','keywords']]\n",
    "styled_df = styled_subset_df.style.set_table_styles({\n",
    "    'title': [{'selector': '',\n",
    "                'props': [('width', '200px'), ('text-align', 'right')]}],\n",
    "    'keywords': [{'selector': '',\n",
    "                'props': [('width', '700px'), ('text-align', 'left')]}]\n",
    "}, overwrite=False).hide(axis=0)\n",
    "# display(styled_df)\n",
    "display (review_mod_df)\n",
    "display (styled_df)\n",
    "del styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list from the \"title\" column using to_list()\n",
    "# These titles will be used in the query for The Movie Database\n",
    "titles_list = review_mod_df['title'].to_list()\n",
    "# print(\"Top 5 Titles:\\n\" + json.dumps(titles_list[:5], indent= 4, ensure_ascii=False)[1:-1])\n",
    "display (titles_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access The Movie Database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Movie Database query\n",
    "url_query   = \"https://api.themoviedb.org/3/search/movie?query=\"\n",
    "url_detail  = \"https://api.themoviedb.org/3/movie/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the results\n",
    "tmbd_movies_list=[]\n",
    "\n",
    "# Create a request counter to sleep the requests after a multiple of 50 requests\n",
    "request_counter = 1\n",
    "'''\n",
    "https://developer.themoviedb.org/docs/rate-limiting\n",
    "While our legacy rate limits have been disabled for some time, \n",
    "we do still have some upper limits to help mitigate needlessly high bulk scraping. \n",
    "They sit somewhere in the 50 requests per second range. \n",
    "This limit could change at any time so be respectful of the service we have built and respect the 429 if you receive one.\n",
    "'''\n",
    "# Loop through the titles\n",
    "for title in titles_list:\n",
    "    # Check if we need to sleep before making a request\n",
    "    if (request_counter % 50) == 0:\n",
    "        print (f'Sleeping at {request_counter} requests')\n",
    "        time.sleep(1)\n",
    "        request_counter += 1\n",
    "    else:\n",
    "    # Add 1 to the request counter\n",
    "        request_counter += 1\n",
    "    # Perform a \"GET\" request for The Movie Database\n",
    "    response=requests.get(f'{url_query}{title}\"&api_key={tmdb_api_key}')\n",
    "    data = response.json()    \n",
    "    # Include a try clause to search for the full movie details.\n",
    "    # Use the except clause to print out a statement if a movie\n",
    "    # is not found. \n",
    "    \n",
    "    try:            \n",
    "        if data['results'] != []:\n",
    "            movie_id = data['results'][0]['id']\n",
    "            # Make a request for the full movie details\n",
    "            # Execute \"GET\" request with url\n",
    "            detail_response = requests.get(f\"{url_detail}{movie_id}?api_key={tmdb_api_key}\")\n",
    "            movie_detail = detail_response.json()\n",
    "\n",
    "            # Extract the genre names into a list\n",
    "            genres_list = [genre['name'] for genre in movie_detail['genres']]\n",
    "            # Extract the spoken_languages' English name into a list\n",
    "            spoken_languages = [spoken_language['english_name'] for spoken_language in movie_detail['spoken_languages']]\n",
    "            # Extract the production_countries' name into a list\n",
    "            production_countries = [production_countries['name'] for production_countries in movie_detail['production_countries']]        \n",
    "            # Add the relevant data to a dictionary and\n",
    "            # append it to the tmdb_movies_list list\n",
    "            tmbd_movies_list.append({\n",
    "                # 'movie_id'        : movie_id,\n",
    "                'title'           : title,\n",
    "                'original_title'  : (movie_detail['original_title']),\n",
    "                'budget'          : (movie_detail['budget']),\n",
    "                'original_language'  : (movie_detail['original_language']),\n",
    "                'homepage'        : (movie_detail['homepage']),\n",
    "                'overview'        : (movie_detail['overview']),\n",
    "                'popularity'      : (movie_detail)['popularity'],\n",
    "                'runtime'         : (movie_detail['runtime']),\n",
    "                'revenue'         : (movie_detail['revenue']),\n",
    "                'release_date'    : (movie_detail['release_date']),\n",
    "                'vote_average'    : (movie_detail['vote_average']),\n",
    "                'vote_count'      : (movie_detail['vote_count']),\n",
    "                'gendre_list'     : genres_list,\n",
    "                'spoken_languages': spoken_languages,\n",
    "                'production_countries': production_countries})\n",
    "                    \n",
    "            # Print out the title that was found\n",
    "            print (f'Found {title}')\n",
    "        else: \n",
    "            raise ValueError (f\"{title} not found.\")   \n",
    "    except ValueError as e:\n",
    "        # Handle the case where no documents are found\n",
    "        print(e)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "    # This catches all exceptions that are requests-related\n",
    "    # Including connection errors, timeouts, etc.\n",
    "        print(\"A network error occurred. Please try again later.\")\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print (json.dumps(tmbd_movies_list[:5],indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a DataFrame\n",
    "tmdb_df = pd.DataFrame(tmbd_movies_list)\n",
    "tmdb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Merge and Clean the Data for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the New York Times reviews and TMDB DataFrames on title\n",
    "merged_df = pd.merge(tmdb_df,review_mod_df, on= 'title', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove list brackets and quotation marks on the columns containing lists\n",
    "# Create a list of the columns that need fixing\n",
    "\n",
    "columns_to_fix = [col for col in merged_df.columns if merged_df[col].map(lambda x: isinstance(x, list)).any()]\n",
    "print (columns_to_fix)\n",
    "# Create a list of characters to remove\n",
    "def clean_list_string(s):\n",
    "    if isinstance(s, list):\n",
    "        # Convert list to string and remove unwanted characters\n",
    "        return str(s).strip('[]').replace('\"', '').replace(\"'\", \"\")\n",
    "    return s\n",
    "\n",
    "# Apply the cleaning directly, no need for preliminary list check\n",
    "for col in columns_to_fix:\n",
    "    merged_df[col] = merged_df[col].apply(clean_list_string)\n",
    "\n",
    "# Display the fixed DataFrame\n",
    "print (merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"byline.person\" column\n",
    "\n",
    "merged_df.drop(columns=['byline.person'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows and reset index\n",
    "duplicates = merged_df[merged_df.duplicated('title')]\n",
    "display (duplicates)\n",
    "merged_df = merged_df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV without the index\n",
    "merged_df.to_csv('tmdb_reviews.csv',index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
